DEBUG - Starting new HTTPS connection (1): en.wikibooks.org:443
DEBUG - https://en.wikibooks.org:443 "GET /wiki/Artificial_Intelligence_for_Computational_Sustainability%3A_A_Lab_Companion%2FMachine_Learning_for_Prediction HTTP/1.1" 200 22474
DEBUG - request status code: 200
DEBUG - Removing unlikely candidate - #mw-content-text.mw-body-content.mw-content-ltr>.printfooter
DEBUG - Removing unlikely candidate - #mw-head>nav#p-personal.vector-menu.mw-portlet.mw-portlet-personal.vector-user-menu-legacy
DEBUG - Removing unlikely candidate - nav#p-personal.vector-menu.mw-portlet.mw-portlet-personal.vector-user-menu-legacy>h3#p-personal-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-personal-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-personal.vector-menu.mw-portlet.mw-portlet-personal.vector-user-menu-legacy>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #left-navigation>nav#p-namespaces.vector-menu.mw-portlet.mw-portlet-namespaces.vector-menu-tabs.vector-menu-tabs-legacy
DEBUG - Removing unlikely candidate - nav#p-namespaces.vector-menu.mw-portlet.mw-portlet-namespaces.vector-menu-tabs.vector-menu-tabs-legacy>h3#p-namespaces-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-namespaces-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-namespaces.vector-menu.mw-portlet.mw-portlet-namespaces.vector-menu-tabs.vector-menu-tabs-legacy>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #left-navigation>nav#p-variants.vector-menu.mw-portlet.mw-portlet-variants.emptyPortlet.vector-menu-dropdown
DEBUG - Removing unlikely candidate - nav#p-variants.vector-menu.mw-portlet.mw-portlet-variants.emptyPortlet.vector-menu-dropdown>input#p-variants-checkbox.vector-menu-checkbox
DEBUG - Removing unlikely candidate - nav#p-variants.vector-menu.mw-portlet.mw-portlet-variants.emptyPortlet.vector-menu-dropdown>label#p-variants-label.vector-menu-heading
DEBUG - Removing unlikely candidate - label#p-variants-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-variants.vector-menu.mw-portlet.mw-portlet-variants.emptyPortlet.vector-menu-dropdown>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #right-navigation>nav#p-views.vector-menu.mw-portlet.mw-portlet-views.vector-menu-tabs.vector-menu-tabs-legacy
DEBUG - Removing unlikely candidate - nav#p-views.vector-menu.mw-portlet.mw-portlet-views.vector-menu-tabs.vector-menu-tabs-legacy>h3#p-views-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-views-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-views.vector-menu.mw-portlet.mw-portlet-views.vector-menu-tabs.vector-menu-tabs-legacy>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #right-navigation>nav#p-cactions.vector-menu.mw-portlet.mw-portlet-cactions.emptyPortlet.vector-menu-dropdown
DEBUG - Removing unlikely candidate - nav#p-cactions.vector-menu.mw-portlet.mw-portlet-cactions.emptyPortlet.vector-menu-dropdown>input#p-cactions-checkbox.vector-menu-checkbox
DEBUG - Removing unlikely candidate - nav#p-cactions.vector-menu.mw-portlet.mw-portlet-cactions.emptyPortlet.vector-menu-dropdown>label#p-cactions-label.vector-menu-heading
DEBUG - Removing unlikely candidate - label#p-cactions-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-cactions.vector-menu.mw-portlet.mw-portlet-cactions.emptyPortlet.vector-menu-dropdown>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #mw-navigation>#mw-panel.vector-legacy-sidebar
DEBUG - Removing unlikely candidate - #mw-panel.vector-legacy-sidebar>nav#p-navigation.vector-menu.mw-portlet.mw-portlet-navigation.vector-menu-portal.portal
DEBUG - Removing unlikely candidate - nav#p-navigation.vector-menu.mw-portlet.mw-portlet-navigation.vector-menu-portal.portal>h3#p-navigation-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-navigation-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-navigation.vector-menu.mw-portlet.mw-portlet-navigation.vector-menu-portal.portal>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #mw-panel.vector-legacy-sidebar>nav#p-community.vector-menu.mw-portlet.mw-portlet-community.vector-menu-portal.portal
DEBUG - Removing unlikely candidate - nav#p-community.vector-menu.mw-portlet.mw-portlet-community.vector-menu-portal.portal>h3#p-community-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-community-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-community.vector-menu.mw-portlet.mw-portlet-community.vector-menu-portal.portal>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #mw-panel.vector-legacy-sidebar>nav#p-tb.vector-menu.mw-portlet.mw-portlet-tb.vector-menu-portal.portal
DEBUG - Removing unlikely candidate - nav#p-tb.vector-menu.mw-portlet.mw-portlet-tb.vector-menu-portal.portal>h3#p-tb-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-tb-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-tb.vector-menu.mw-portlet.mw-portlet-tb.vector-menu-portal.portal>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #mw-panel.vector-legacy-sidebar>nav#p-sister_projects.vector-menu.mw-portlet.mw-portlet-sister_projects.vector-menu-portal.portal
DEBUG - Removing unlikely candidate - nav#p-sister_projects.vector-menu.mw-portlet.mw-portlet-sister_projects.vector-menu-portal.portal>h3#p-sister_projects-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-sister_projects-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-sister_projects.vector-menu.mw-portlet.mw-portlet-sister_projects.vector-menu-portal.portal>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #mw-panel.vector-legacy-sidebar>nav#p-coll-print_export.vector-menu.mw-portlet.mw-portlet-coll-print_export.vector-menu-portal.portal
DEBUG - Removing unlikely candidate - nav#p-coll-print_export.vector-menu.mw-portlet.mw-portlet-coll-print_export.vector-menu-portal.portal>h3#p-coll-print_export-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-coll-print_export-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-coll-print_export.vector-menu.mw-portlet.mw-portlet-coll-print_export.vector-menu-portal.portal>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - #mw-panel.vector-legacy-sidebar>nav#p-lang.vector-menu.mw-portlet.mw-portlet-lang.vector-menu-portal.portal
DEBUG - Removing unlikely candidate - nav#p-lang.vector-menu.mw-portlet.mw-portlet-lang.vector-menu-portal.portal>h3#p-lang-label.vector-menu-heading
DEBUG - Removing unlikely candidate - h3#p-lang-label.vector-menu-heading>span.vector-menu-heading-label
DEBUG - Removing unlikely candidate - nav#p-lang.vector-menu.mw-portlet.mw-portlet-lang.vector-menu-portal.portal>.vector-menu-content
DEBUG - Removing unlikely candidate - .vector-menu-content>ul.vector-menu-content-list
DEBUG - Removing unlikely candidate - body#readabilityBody.skin-vector-legacy.mediawiki.ltr.sitedir-ltr.mw-hide-empty-elt.ns-0.ns-subject.mw-editable.page-Artificial_Intelligence_for_Computational_Sustainability_A_Lab_Companion_Machine_Learning_for_Prediction.rootpage-Artificial_Intelligence_for_Computational_Sustainability_A_Lab_Companion.skin-vector.action-view>footer#footer.mw-footer
DEBUG - Removing unlikely candidate - footer#footer.mw-footer>ul#footer-info
DEBUG - Removing unlikely candidate - ul#footer-info>li#footer-info-lastmod
DEBUG - Removing unlikely candidate - ul#footer-info>li#footer-info-copyright
DEBUG - Removing unlikely candidate - footer#footer.mw-footer>ul#footer-places
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-privacy
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-about
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-disclaimers
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-wm-codeofconduct
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-mobileview
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-developers
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-statslink
DEBUG - Removing unlikely candidate - ul#footer-places>li#footer-places-cookiestatement
DEBUG - Removing unlikely candidate - footer#footer.mw-footer>ul#footer-icons.noprint
DEBUG - Removing unlikely candidate - ul#footer-icons.noprint>li#footer-copyrightico
DEBUG - Removing unlikely candidate - ul#footer-icons.noprint>li#footer-poweredbyico
DEBUG - Branch 58.440 #content.mw-body>#bodyContent.vector-body link density 0.088 -> 53.322
DEBUG - Branch 56.720 body#readabilityBody.skin-vector-legacy.mediawiki.ltr.sitedir-ltr.mw-hide-empty-elt.ns-0.ns-subject.mw-editable.page-Artificial_Intelligence_for_Computational_Sustainability_A_Lab_Companion_Machine_Learning_for_Prediction.rootpage-Artificial_Intelligence_for_Computational_Sustainability_A_Lab_Companion.skin-vector.action-view>#content.mw-body link density 0.087 -> 51.771
DEBUG - Branch 307.440 #mw-content-text.mw-body-content.mw-content-ltr>.mw-parser-output link density 0.082 -> 282.382
DEBUG - Branch 206.220 #bodyContent.vector-body>#mw-content-text.mw-body-content.mw-content-ltr link density 0.082 -> 189.412
DEBUG - Branch  7.380 .trow>.tsingle link density 0.000 ->  7.380
DEBUG - Branch  7.390 .thumbinner>.trow link density 0.000 ->  7.390
DEBUG - Branch  7.400 .trow>.tsingle link density 0.000 ->  7.400
DEBUG - Top 5 : 282.382 #mw-content-text.mw-body-content.mw-content-ltr>.mw-parser-output
DEBUG - Top 5 : 189.412 #bodyContent.vector-body>#mw-content-text.mw-body-content.mw-content-ltr
DEBUG - Top 5 : 53.322 #content.mw-body>#bodyContent.vector-body
DEBUG - Top 5 : 51.771 body#readabilityBody.skin-vector-legacy.mediawiki.ltr.sitedir-ltr.mw-hide-empty-elt.ns-0.ns-subject.mw-editable.page-Artificial_Intelligence_for_Computational_Sustainability_A_Lab_Companion_Machine_Learning_for_Prediction.rootpage-Artificial_Intelligence_for_Computational_Sustainability_A_Lab_Companion.skin-vector.action-view>#content.mw-body
DEBUG - Top 5 :  7.400 .trow>.tsingle
DEBUG - Not removing .mw-parser-output>ul of length 49: instructions.txt maxent.bat maxent.jar r...
DEBUG - Not removing .mw-parser-output>ul of length 30: climate-maps.pdf variables.pdf
DEBUG - Not removing .mw-parser-output>ul of length 58: environmentBaseTemp environmentIncrTemp ...
DEBUG - Not removing .mw-parser-output>ul of length 126: Decision trees Ensembles Classifiers k-N...
DEBUG - Removed  0.000 li.toclevel-1.tocsection-14>ul with weight 0 cause it has too many links 0.990 for its weight 0.
DEBUG - Removed  0.000 li.toclevel-1.tocsection-11>ul with weight 0 cause it has too many links 0.988 for its weight 0.
DEBUG - Removed  0.000 li.toclevel-2.tocsection-4>ul with weight 0 cause it has too many links 0.985 for its weight 0.
DEBUG - Removed  0.000 li.toclevel-1.tocsection-2>ul with weight 0 cause it has too many links 0.987 for its weight 0.
DEBUG - Removed  0.000 #toc.toc>ul with weight 0 cause it has too many links 0.966 for its weight 0.
DEBUG - Removed  0.000 .tsingle>.thumbimage with weight 0 cause it has no content.
DEBUG - Removed  7.390 .trow>.tsingle with weight 0 cause it has too short content length 23 without a single image.
DEBUG - Removed  7.400 .tsingle>.thumbimage with weight 0 cause it has no content.
DEBUG - Not removing .trow>.tsingle of length 40: Response curve of the Jeffrey pine model...
DEBUG - Removed  7.380 .tsingle>.thumbimage with weight 0 cause it has no content.
DEBUG - Not removing .trow>.tsingle of length 38: Predicted distribution of Jeffrey pine
DEBUG - Not removing .thumbinner>.trow of length 78: Predicted distribution of Jeffrey pineRe...
DEBUG - Not removing .thumb.tmulti.tnone.center>.thumbinner of length 78: Predicted distribution of Jeffrey pineRe...
DEBUG - Not removing .mw-parser-output>.thumb.tmulti.tnone.center of length 78: Predicted distribution of Jeffrey pineRe...
DEBUG - Removed 282.382 .mw-parser-output>#toc.toc with weight 0 cause it has less than 3x <p>s than <input>s.
INFO - type of dense tag: <class 'str'>
DEBUG - "Machine learning for purposes of predicting properties of objects and events -- as opposed to machine learning for purposes on improving search, planning and problem solving -- is the dominant form of machine learning studied (though the latter is often usefully understood in terms of the former).AI textbooks that include substantive machine learning content, particularly of the type described in this chapter of the lab companion include Russell and Norvig, 2010[1], Chapter V; Poole and Mackworth, 2010[2], Chapter 7 and Sections 11.1-11.2; Luger, 2009[3], Chapters 10-11.In addition, there are several textbooks on machine learning (Hastie, et al, 2009[4];Langley, 1996[5]; Mitchell, 1997 [6]) and other online resources, such as Ng's (2011) online videos[7].A list of machine learning concepts is available from List_of_machine_learning_concepts describing supervised learning, unsupervised learning, semi-supervised learning, deep learning and reinforcement learning"
DEBUG - 'Supervised Learning involves inferring functions for classifications of inputs to desired output value.Examples of supervised learning are the following:\r\nThe distribution of each species is determined by a combination of factors, including climate, resources, and dependence on other species.This unique combination of factors determines where different species can live successfully.Even if a single species could survive in a particular climate and habitat, they may not have the resources to survive or reproduce.Consider the example of Joshua trees, which are confined to elevations between 400-1800 m (2,000-6000 ft.) in the Mojave Desert.For Joshua trees to grow any lower than 400 m or any further south than the Mojave Desert would be suicide by drought.However, they grew lower in elevation and further south during the cooler and wetter climate of the last glacial period.This means that Joshua trees expand their range when they can.So why don’t they live in coastal southern California? If a Joshua tree could take a coastal vacation, it would likely find the climate to be ideal for growth'
DEBUG - "However, it would never reproduce.To reproduce, Joshua trees depend on a variety of  yucca moth that is genetically programmed for stuffing a little ball of pollen into the cup-shaped stigma of Joshua tree flowers.This relationship is mutually vital for both plant and moth, and for a complexity of reasons that are not fully understood, the Mojave Desert is where these two species live together.In this lab, you will examine the effects of climate and climate change on the distributions of several species of tree, and then use climate and species-range data to construct computational models of species distribution using maximum entropy modeling (also known as Maxent)[9][10][11].Maxent is a general method from information theory for finding the probability distribution that has maximum entropy (i.e., is the most non-committal, or closest to a uniform distribution), subject to a set of constraints that represent our partial knowledge of the target distribution.In this case, we have partial knowledge of the species' presence at specific points over the map; these known sample points serve as the constraints on the probability distributions.The goal of Maxent is to generalize these samples, following the principle of maximum entropy, to estimate the species distribution over the entire map.Each location on the map, including the known samples, is characterized by a set of climate variables, such as mean annual temperature, mean diurnal temperature range, mean precipitation during the coldest quarter of the year, etc.The species distribution is learned in this multi-dimensional feature space"
DEBUG - 'This lab is designed to augment in-class discussions on Maxent and species distribution modeling.It can be divided over multiple weeks based on the sections below.To get started, download this zip file containing all data files needed for this lab.The zip file is approximately 74M and requires approximately 400M when uncompressed.It includes the species presence data, environmental data, a pdf of the climate maps, and a pdf describing each of the climate variables.The Maxent software must be downloaded separately from http://www.cs.princeton.edu/~schapire/maxent/.These instructions were written for version 3.3.3k of the Maxent software, and so we recommend downloading that same version of the software.These instructions may need to be adapted for subsequent versions.Once you uncompress the zip file, you should have the following directories:\r\nand two files:\r\nInstall the Maxent software to the maxent directory'
DEBUG - 'Inside the maxent directory, you should now have four files:\r\nYou are now ready to continue with the rest of the lab.Examine the maps of California in climate-maps.pdf, which is available in the zip file downloaded in the Getting Started section.Each map depicts a single climate variable.Overlaid on each climate map are maps of six species’ ranges:  bigcone Douglas fir (Pseudotsuga macrocarpa), Bishop pine (Pinus muricata), Blue oak (Quercus douglasii), Jeffrey pine (Pinus jeffreyi), coast redwood (Sequoia sempervirens), and giant sequoia (Sequoia giganteum).After studying the maps, answer the following questions:\r\nThe Maxent software [1] for species distribution modeling was developed in a collaboration between machine learning researchers and a biologist (emphasizing the interdisciplinary nature of computational sustainability) in 2004.It is a recent contribution from computer science / artificial intelligence that is now used widely by biologists and ecologists.To learn the species distribution models, Maxent takes two inputs: (1) a file containing exact locations where a species of interest is known to grow and (2) a file containing climate data for each of those locations.By evaluating the climate data at each location where the species of interest is present, Maxent calculates a probability function that describes the chances of a tree location having any given climate setting.So if we were studying Joshua trees, Maxent would predict that if a Joshua tree is growing in a given location, there is a high probability that that location is hot rather than cold during summer'
DEBUG - "Next, Maxent flips this probability function around to predict the probability of species presence given a particular climate type.Therefore, Maxent would predict a high likelihood of Joshua tree presence in locations that are hot during summer and a low likelihood of presence in locations that are cold during summer.While this example focused on only one climate variable, Maxent generates the model and predicts the presence likelihood using multiple climate variables.Details on precisely how Maxent learns the model are given in the journal article by Phillips, Anderson, and Schapire (2006)[12].Instructions to download and install the Maxent software are included in the Getting Started section.The data required by Maxent is included in the following three folders in the zip file:\r\nThe file variables.pdf contains textual descriptions of each of the climate parameters.To learn a computational model for the distribution of each of your two species:  (Read these directions completely before you build your first model!)\r\nEach output folder will contain a .html webpage that summarizes the model's information, including the predicted species distribution overlayed on a map and several performance curves, as shown in the figures below.Cooler colors (blue/green) indicate areas where the model calculates a low probability of species presence and warmer colors (red/yellow) indicate areas where the model calculates a higher probability of species presence.White squares indicate the locations specified in your species presence file"
DEBUG - 'For the response curve (middle figure), the x-axis represents a variety of climate values (in this case the annual precipitation in mm) and the y-axis indicates the probability of finding the species of interest in an area with any given annual precipitation.So, the response curve below indicates that Jeffrey pine trees are most likely present in areas with an annual precipitation greater than 600mm.The rightmost figure depicts the receiver operating characteristic (ROC) curve for the model.The ROC curve depicts the classification performance of the model under different discrimination thresholds.The plot can be turned into a single summary statistic by taking the area under the ROC curve (AUC), but note that the AUC loses information about the tradeoffs in the model\'s performance in different regions.[13] Notice that the ROC curve lies in the unit square, so a model with perfect (100%) accuracy would have the red line go all the way to the upper left (coordinates (0,1)) and would have area 1 (although this is seldom achieved).The black line indicates the performance of random guessing, and so it has 50% accuracy and an AUC of 0.5.  If the red line is below (to the right of) the black line, this indicates that we could have done better simply by random guessing.The AUC for this example is 0.86 as noted in the graph\'s legend (this is called the "training AUC" of the model).Note that this does NOT guarantee that the model will have an AUC of 0.86 for unseen data; in fact, the training accuracy is often a poor indication of general model performance (called "test accuracy" or "generalization accuracy").To complete your analysis:\r\nIn this section, we will build predictive models that combine information from multiple climate parameters to make stronger predictions'
DEBUG - 'Look at the response curves for each of your two new models.Note that the top and bottom rows of response curves look different even though they represent the same climate variables.The bottom curves represent what each response curve would look like if it were the only variable used to predict the probability of species presence.The top curves show the actual relationships between all climate variables and species presence in your new model.The multivariate model may indicate a wider response range for a variable than was discovered using that variable alone.Pick the single species and distribution model that interest you the most.Label and paste all response curves (top and bottom) from that new model into your lab write-up.Much of the western United States became warmer during the 1900s.This warming is expected to continue for many years to come as a result of an increase in the amount of long-wave radiation emitted towards the ground by greenhouse gas molecules like CO2, CH3, and H2O'
DEBUG - 'This is likely to affect forests substantially.Species living in hot, dry regions are likely to suffer as evapotranspiration rates (and thus drought) increase.Species living in cold regions may benefit as warmer temperatures may allow for photosynthesis earlier in the spring and later in the fall.These changes are likely to impact forests most substantially at their boundaries, where trees stand on the front lines of a constant battle between survival and death.If temperatures warm, new seedlings and mature trees growing at the upper elevation tree line in the Sierra Nevadas will die less often and the upper tree line will rise.If evapotranspiration increases, new seedlings and mature trees growing on the lower elevation tree line between alpine forest above and desert scrub below will die more often and the lower tree line will also rise.This is how the edges of populations move when climate changes.In this section, you will use the last multivariable model that you created in the previous section, and apply it to new climate data that assume a hypothetical change of 4°C.While real temperature change will be very spatially, seasonally, and diurnally variable (warming should be most substantial near poles, during winter, and at night), this hypothetical temperature change is applied everywhere at all times'
DEBUG - "So, we are assuming that diurnal temperature range and annual temperature range are unchanged.We also assume that rainfall is unchanged.Instructor Summary for Species Distribution Modeling Lab\nExample: OSU work on identifying anthropods\r\nRegression is the problem of learning to predict an object's value along a continuously-valued  dependent dimension (or variable) given the object's description along independent dimensions (or variables).Material on regression that would be necessary to complete many of the assignments in this section can be found in a variety of sources, including Russell and Norvig, 2010[1], section 18.6, pp.717-723; Poole and Mackworth, 2010[2], section 7.3.2, pp.304-305; Ng, 2011[7], videos II, IV.This material is almost entirely focused on linear regression, however (though this is sufficient for some assignments of this section).Few undergraduate textbooks go significantly into other forms of regression, such as polynomial regression and tree-structured regression, but these texts typically provide ample material for instructors and the lab text to get into these issues, perhaps with pointers to other online content that is created in response to the lab text’s coverage.For example, polynomial regression is realized by adding higher-order terms to the data, then using the machinery of linear regression"
DEBUG - 'A second form, of regression tree induction, is typically mentioned in AI textbooks as a variant of decision tree induction, which universally gets substantial coverage.An important aspect of both regression (and decision) trees is that they make explicit the important principle of "context" through the strategy of recursive decomposition – some variables may be informative in some contexts (e.g., subtrees), but not others.To include regression tree analysis, however, would undoubtedly require more tutorial information.The subject of regression trees is a good example of purely AI educational content that might be created in Wikipedia as a result of the work on the sustainability lab text in Wikibooks; there is currently no “regression tree” article in Wikipedia, a remarkable omission, though there is a reference to regression trees from Wikipedia’s “Decision Trees (for machine learning)” article.Repeating a desire expressed in Artificial Intelligence for Computational Sustainability: A Lab Companion/Introduction and Artificial Intelligence for Computational Sustainability: A Lab Companion/Guide for Contributors, editors might be motivated to add Regression Tree pages to Wikipedia as a result of this lab\'s activity.Quantitative measures of environmental impact enable computational and mathematical analyses of sustainability problems.Further, these measures facilitate visualization and other modalities for communication of environmental consequences to the public, policy makers and scientists.Formally, an ecological footprint (Wackernagel and Rees 1996; Global Footprint Network, 2012) is the amount of land (e.g., in hectares) that is needed to sustain indefinitely, without degradation, a process or entity, ranging in scale from (manufacture, use, and disposal of) individual artifacts to cities, nations and the world’s human population.Informally, the term “ecological footprint” refers to many kinds measures, such as greenhouse-gas and energy equivalence of a process or thing'
DEBUG - 'Because an ecological footprint is typically a continuous value, it may be that regression can be used to learn an effective predictor.In supervised learning there is (typically) one attribute or variable, called the dependent variable, that is the focus of attention -- the goal of supervised learning from labeled data is to optimize prediction performance of this one dependent variable given some or all of the values of the remaining independent variables.In contrast, unsupervised learning can be cast as a problem in which no one variable is the exclusive focus of attention, but rather a system might be called upon to make predictions along any variables with unknown values, given known values for other variables.In this case, the goal of unsupervised learning is to optimize some composite prediction performance (undoubtedly with many interesting variants) across all (or perhaps selected) variables.This performance task is perhaps most obvious as the goal in unsupervised learning of (Bayesian) belief networks, but it can be equally regarded as a goal of clustering and association rule learning[14].This unsupervised performance task, as elaborated in the context of clustering for flexible prediction or pattern completion[15][16] is a precursor to multitask learning as described by Caruana (1997)[17] There are other forms of unsupervised learning, most notably topic modeling [18] that can also be viewed along the lines of prediction performance.Importantly, the treatments and presentations of unsupervised learning are generally much more varied and less predictable than the treatments of supervised learning, probably for a variety of reasons.Nonetheless, the unsupervised performance task as outlined here is a simple unifying theme across unsupervised methods and the reason the we place unsupervised learning under Machine Learning for Prediction.Unsupervised learning, such as belief network learning and clustering, can be used to discover, represent, and exploit statistical relationships between features and objects (e.g., people, processes, artifacts) for purposes of contextualizing and predicting ecological footprints'
DEBUG - ---
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'Machine learning for purposes of predicting properties of objects and events -- as opposed to machine learning for purposes on improving search, planning and problem solving -- is the dominant form of machine learning studied (though the latter is often usefully understood in terms of the former).AI textbooks that include substantive machine learning content, particularly of the type described in this chapter of the lab companion include Russell and Norvig, 2010.A list of machine learning concepts is available from Listofmachinelearningconcepts describing supervised learning, unsupervised learning, semi-supervised learning, deep learning and reinforcement learning'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'Supervised Learning involves inferring functions for classifications of inputs to desired output value.Examples of supervised learning are the following:\r The distribution of each species is determined by a combination of factors, including climate, resources, and dependence on other species.This unique combination of factors determines where different species can live successfully.Even if a single species could survive in a particular climate and habitat, they may not have the resources to survive or reproduce.Consider the example of Joshua trees, which are confined to elevations between 400-1800 m (2,000-6000 ft.) in the Mojave Desert.For Joshua trees to grow any lower than 400 m or any further south than the Mojave Desert would be suicide by drought.However, they grew lower in elevation and further south during the cooler and wetter climate of the last glacial period.This means that Joshua trees expand their range when they can.So why dont they live in coastal southern California? If a Joshua tree could take a coastal vacation, it would likely find the climate to be ideal for growth'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - "However, it would never reproduce.To reproduce, Joshua trees depend on a variety of  yucca moth that is genetically programmed for stuffing a little ball of pollen into the cup-shaped stigma of Joshua tree flowers.This relationship is mutually vital for both plant and moth, and for a complexity of reasons that are not fully understood, the Mojave Desert is where these two species live together.In this lab, you will examine the effects of climate and climate change on the distributions of several species of tree, and then use climate and species-range data to construct computational models of species distribution using maximum entropy modeling (also known as Maxent).Maxent is a general method from information theory for finding the probability distribution that has maximum entropy (i.e., is the most non-committal, or closest to a uniform distribution), subject to a set of constraints that represent our partial knowledge of the target distribution.In this case, we have partial knowledge of the species' presence at specific points over the map; these known sample points serve as the constraints on the probability distributions.The goal of Maxent is to generalize these samples, following the principle of maximum entropy, to estimate the species distribution over the entire map.Each location on the map, including the known samples, is characterized by a set of climate variables, such as mean annual temperature, mean diurnal temperature range, mean precipitation during the coldest quarter of the year, etc.The species distribution is learned in this multi-dimensional feature space"
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'This lab is designed to augment in-class discussions on Maxent and species distribution modeling.It can be divided over multiple weeks based on the sections below.To get started, download this zip file containing all data files needed for this lab.The zip file is approximately 74M and requires approximately 400M when uncompressed.It includes the species presence data, environmental data, a pdf of the climate maps, and a pdf describing each of the climate variables.The Maxent software must be downloaded separately from http://www.cs.princeton.edu/~schapire/maxent/.These instructions were written for version 3.3.3k of the Maxent software, and so we recommend downloading that same version of the software.These instructions may need to be adapted for subsequent versions.Once you uncompress the zip file, you should have the following directories:\r and two files:\r Install the Maxent software to the maxent directory'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'Inside the maxent directory, you should now have four files:\r You are now ready to continue with the rest of the lab.Examine the maps of California in climate-maps.pdf, which is available in the zip file downloaded in the Getting Started section.Each map depicts a single climate variable.Overlaid on each climate map are maps of six species ranges:  bigcone Douglas fir (Pseudotsuga macrocarpa), Bishop pine (Pinus muricata), Blue oak (Quercus douglasii), Jeffrey pine (Pinus jeffreyi), coast redwood (Sequoia sempervirens), and giant sequoia (Sequoia giganteum).After studying the maps, answer the following questions:\r The Maxent software  for species distribution modeling was developed in a collaboration between machine learning researchers and a biologist (emphasizing the interdisciplinary nature of computational sustainability) in 2004.It is a recent contribution from computer science / artificial intelligence that is now used widely by biologists and ecologists.To learn the species distribution models, Maxent takes two inputs: (1) a file containing exact locations where a species of interest is known to grow and (2) a file containing climate data for each of those locations.By evaluating the climate data at each location where the species of interest is present, Maxent calculates a probability function that describes the chances of a tree location having any given climate setting.So if we were studying Joshua trees, Maxent would predict that if a Joshua tree is growing in a given location, there is a high probability that that location is hot rather than cold during summer'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - "Next, Maxent flips this probability function around to predict the probability of species presence given a particular climate type.Therefore, Maxent would predict a high likelihood of Joshua tree presence in locations that are hot during summer and a low likelihood of presence in locations that are cold during summer.While this example focused on only one climate variable, Maxent generates the model and predicts the presence likelihood using multiple climate variables.Details on precisely how Maxent learns the model are given in the journal article by Phillips, Anderson, and Schapire (2006).Instructions to download and install the Maxent software are included in the Getting Started section.The data required by Maxent is included in the following three folders in the zip file:\r The file variables.pdf contains textual descriptions of each of the climate parameters.To learn a computational model for the distribution of each of your two species:  (Read these directions completely before you build your first model!)\r Each output folder will contain a .html webpage that summarizes the model's information, including the predicted species distribution overlayed on a map and several performance curves, as shown in the figures below.Cooler colors (blue/green) indicate areas where the model calculates a low probability of species presence and warmer colors (red/yellow) indicate areas where the model calculates a higher probability of species presence.White squares indicate the locations specified in your species presence file"
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'For the response curve (middle figure), the x-axis represents a variety of climate values (in this case the annual precipitation in mm) and the y-axis indicates the probability of finding the species of interest in an area with any given annual precipitation.So, the response curve below indicates that Jeffrey pine trees are most likely present in areas with an annual precipitation greater than 600mm.The rightmost figure depicts the receiver operating characteristic (ROC) curve for the model.The ROC curve depicts the classification performance of the model under different discrimination thresholds.The plot can be turned into a single summary statistic by taking the area under the ROC curve (AUC), but note that the AUC loses information about the tradeoffs in the model\'s performance in different regions. Notice that the ROC curve lies in the unit square, so a model with perfect (100%) accuracy would have the red line go all the way to the upper left (coordinates (0,1)) and would have area 1 (although this is seldom achieved).The black line indicates the performance of random guessing, and so it has 50% accuracy and an AUC of 0.5.  If the red line is below (to the right of) the black line, this indicates that we could have done better simply by random guessing.The AUC for this example is 0.86 as noted in the graph\'s legend (this is called the "training AUC" of the model).Note that this does NOT guarantee that the model will have an AUC of 0.86 for unseen data; in fact, the training accuracy is often a poor indication of general model performance (called "test accuracy" or "generalization accuracy").To complete your analysis:\r In this section, we will build predictive models that combine information from multiple climate parameters to make stronger predictions'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'Look at the response curves for each of your two new models.Note that the top and bottom rows of response curves look different even though they represent the same climate variables.The bottom curves represent what each response curve would look like if it were the only variable used to predict the probability of species presence.The top curves show the actual relationships between all climate variables and species presence in your new model.The multivariate model may indicate a wider response range for a variable than was discovered using that variable alone.Pick the single species and distribution model that interest you the most.Label and paste all response curves (top and bottom) from that new model into your lab write-up.Much of the western United States became warmer during the 1900s.This warming is expected to continue for many years to come as a result of an increase in the amount of long-wave radiation emitted towards the ground by greenhouse gas molecules like CO2, CH3, and H2O'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'This is likely to affect forests substantially.Species living in hot, dry regions are likely to suffer as evapotranspiration rates (and thus drought) increase.Species living in cold regions may benefit as warmer temperatures may allow for photosynthesis earlier in the spring and later in the fall.These changes are likely to impact forests most substantially at their boundaries, where trees stand on the front lines of a constant battle between survival and death.If temperatures warm, new seedlings and mature trees growing at the upper elevation tree line in the Sierra Nevadas will die less often and the upper tree line will rise.If evapotranspiration increases, new seedlings and mature trees growing on the lower elevation tree line between alpine forest above and desert scrub below will die more often and the lower tree line will also rise.This is how the edges of populations move when climate changes.In this section, you will use the last multivariable model that you created in the previous section, and apply it to new climate data that assume a hypothetical change of 4°C.While real temperature change will be very spatially, seasonally, and diurnally variable (warming should be most substantial near poles, during winter, and at night), this hypothetical temperature change is applied everywhere at all times'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - "So, we are assuming that diurnal temperature range and annual temperature range are unchanged.We also assume that rainfall is unchanged.Instructor Summary for Species Distribution Modeling Lab Example: OSU work on identifying anthropods\r Regression is the problem of learning to predict an object's value along a continuously-valued  dependent dimension (or variable) given the object's description along independent dimensions (or variables).Material on regression that would be necessary to complete many of the assignments in this section can be found in a variety of sources, including Russell and Norvig, 2010, videos II, IV.This material is almost entirely focused on linear regression, however (though this is sufficient for some assignments of this section).Few undergraduate textbooks go significantly into other forms of regression, such as polynomial regression and tree-structured regression, but these texts typically provide ample material for instructors and the lab text to get into these issues, perhaps with pointers to other online content that is created in response to the lab texts coverage.For example, polynomial regression is realized by adding higher-order terms to the data, then using the machinery of linear regression"
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'A second form, of regression tree induction, is typically mentioned in AI textbooks as a variant of decision tree induction, which universally gets substantial coverage.An important aspect of both regression (and decision) trees is that they make explicit the important principle of "context" through the strategy of recursive decomposition  some variables may be informative in some contexts (e.g., subtrees), but not others.To include regression tree analysis, however, would undoubtedly require more tutorial information.The subject of regression trees is a good example of purely AI educational content that might be created in Wikipedia as a result of the work on the sustainability lab text in Wikibooks; there is currently no regression tree article in Wikipedia, a remarkable omission, though there is a reference to regression trees from Wikipedias Decision Trees (for machine learning) article.Repeating a desire expressed in Artificial Intelligence for Computational Sustainability: A Lab Companion/Introduction and Artificial Intelligence for Computational Sustainability: A Lab Companion/Guide for Contributors, editors might be motivated to add Regression Tree pages to Wikipedia as a result of this lab\'s activity.Quantitative measures of environmental impact enable computational and mathematical analyses of sustainability problems.Further, these measures facilitate visualization and other modalities for communication of environmental consequences to the public, policy makers and scientists.Formally, an ecological footprint (Wackernagel and Rees 1996; Global Footprint Network, 2012) is the amount of land (e.g., in hectares) that is needed to sustain indefinitely, without degradation, a process or entity, ranging in scale from (manufacture, use, and disposal of) individual artifacts to cities, nations and the worlds human population.Informally, the term ecological footprint refers to many kinds measures, such as greenhouse-gas and energy equivalence of a process or thing'
DEBUG - 'Artificial Intelligence for Computational Sustainability: A Lab Companion/Machine Learning for Prediction - Wikibooks, open books for an open world'
DEBUG - False
DEBUG - 'Because an ecological footprint is typically a continuous value, it may be that regression can be used to learn an effective predictor.In supervised learning there is (typically) one attribute or variable, called the dependent variable, that is the focus of attention -- the goal of supervised learning from labeled data is to optimize prediction performance of this one dependent variable given some or all of the values of the remaining independent variables.In contrast, unsupervised learning can be cast as a problem in which no one variable is the exclusive focus of attention, but rather a system might be called upon to make predictions along any variables with unknown values, given known values for other variables.In this case, the goal of unsupervised learning is to optimize some composite prediction performance (undoubtedly with many interesting variants) across all (or perhaps selected) variables.This performance task is perhaps most obvious as the goal in unsupervised learning of (Bayesian) belief networks, but it can be equally regarded as a goal of clustering and association rule learning that can also be viewed along the lines of prediction performance.Importantly, the treatments and presentations of unsupervised learning are generally much more varied and less predictable than the treatments of supervised learning, probably for a variety of reasons.Nonetheless, the unsupervised performance task as outlined here is a simple unifying theme across unsupervised methods and the reason the we place unsupervised learning under Machine Learning for Prediction.Unsupervised learning, such as belief network learning and clustering, can be used to discover, represent, and exploit statistical relationships between features and objects (e.g., people, processes, artifacts) for purposes of contextualizing and predicting ecological footprints'
DEBUG - ---
DEBUG - {'max_length': 130, 'min_length': 30, 'do_sample': False}
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 244
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 292
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 320
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 271
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 255
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 243
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 292
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 192
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 348
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 213
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
ERROR - ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    response = conn.getresponse()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\http\client.py", line 1375, in getresponse
    response.begin()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connectionpool.py", line 844, in urlopen
    retries = retries.increment(
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\util\retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    response = conn.getresponse()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\urllib3\connection.py", line 461, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\http\client.py", line 1375, in getresponse
    response.begin()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\VISION\Desktop 2\PROJECT_FORTH_YEAR\Edu-Presentation-Maker\presentation_genrating_stage\presentation_generation\BartLargeCnnGenerator.py", line 54, in request_summary
    response = requests.post(self.API_URL, headers=self.HEADERS
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\VISION\anaconda3\envs\source_project\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 207
DEBUG - status code : 200
DEBUG - Starting new HTTPS connection (1): api-inference.huggingface.co:443
DEBUG - https://api-inference.huggingface.co:443 "POST /models/facebook/bart-large-cnn HTTP/1.1" 200 388
DEBUG - status code : 200
DEBUG - keypoints generated successfully
DEBUG - [[<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C3A0>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C430>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C820>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CAC0>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CC10>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C520>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CA30>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C670>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CDC0>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C580>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CE80>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CEB0>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CB50>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C640>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C5B0>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9D060>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9D090>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CDF0>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9CE20>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C8E0>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C610>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9C7F0>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9D360>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9D810>], [<data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9D480>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9E020>, <data_objects.KeyPoint.KeyPoint object at 0x0000018F93A9DF60>]]
DEBUG - presentation organized successfully
DEBUG - [<data_objects.Slide.Slide object at 0x0000018F93A7BDF0>, <data_objects.Slide.Slide object at 0x0000018F93A7BAF0>, <data_objects.Slide.Slide object at 0x0000018F93A7BBB0>, <data_objects.Slide.Slide object at 0x0000018F93A7BB50>, <data_objects.Slide.Slide object at 0x0000018F93A7BDC0>, <data_objects.Slide.Slide object at 0x0000018F93A7BD30>, <data_objects.Slide.Slide object at 0x0000018F93A7BC70>, <data_objects.Slide.Slide object at 0x0000018F93A7BEE0>, <data_objects.Slide.Slide object at 0x0000018F93A7BE80>, <data_objects.Slide.Slide object at 0x0000018F93A7BD00>, <data_objects.Slide.Slide object at 0x0000018F93A7BEB0>, <data_objects.Slide.Slide object at 0x0000018F93A7BFD0>]
DEBUG - Presentation exported successfully
